## 主要内容
[1. 机器学习的特点与功能](#1)
[2. 机器学习算法的分类](#2)
[3. 机器学习的要素](#3)
[4. 机器学习模型与求解](#4)
[5. 经验风险与结构风险](#5)
[6. 模型的评估与选择](#6)

---

<h4 id='1'>机器学习的特点与功能</h4>

- 以数据和特征为基础，是数据驱动的科学
- 功能：对数据进行预测与分析
- 以模型方法为中心
- 以概率论、统计学、信息论、计算理论、最优化以及计算机科学等多领域交叉

---

<h4 id='2'>机器学习算法的分类</h4>

- 有监督学习：特征向量 + 类别标签
    - 分类算法：类标离散，种类有限
        - KNN
        - 决策树
        - SVM
        - 朴素贝叶斯
        - 随机森林
        - 逻辑回归
        - 神经网络
    - 回归算法：类标连续，种类无限
        - 线性回归
        - 决策树
        - GBDT
- 无监督学习：只有特征向量，没有标签；特征相似的聚集在一起=聚类≠分类
    - K-Means
    - DBSCAN
    - 层次聚类
    - 高斯混合
- 半监督学习：样本不足/类标很少，不浪费已有的类标，结合有监督和无监督学习的学习方式
    - 原始数据 -->无监督聚类--> 聚类结果（A）
    - 原始有标签数据+A --> 有监督分类 --> 预测数据
- 强化学习
    - 智能系统从环境到行为映射的学习，使得奖励信号（强化信号）函数值最大，在行动-评价的环境中获得知识，改进行动方案以适应环境

---

<h4 id='3'>机器学习的要素</h4>

- 数据与特征决定了机器学习的上限
- 模型与算法可以无限逼近这个上限

1. 特征
    - 机器学习算法的输入向量的每一维
2. 模型
    - 机器学习训练的过程中所要学习的条件概率分布或者决策函数
3. 策略
    - 使用一种什么样的评价，度量模型训练过程中的学习好坏，根据这个方法区实施和调整模型的参数，以期望训练的模型将来对未知的数据具有最好的预测准确度
4. 算法
    - 模型的具体计算方法，基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后考虑用什么样的计算方法去求解这个最优模型

---

<h4 id='4'>机器学习模型与求解</h4>

- 样本集合：$T = \{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}$
- 单个样本：$\begin{cases} 
    x_i = (x^{(1)},x^{(2)},...,x^{(i)},...,x^{(n)})^T\\
    y_i = (y^{(1)})
    \end{cases}$
    - N：样本数量
    - x：特征向量（n维）
    - y：类标（一维）
- 目标：$x_i' = (x^{(1)},x^{(2)},...,x^{(i)},...,x^{(n)})^T \Rightarrow y_i' = ?$
    - 对于任意给定的$x_i'$能够预测出它的类标$y_i'$

求解
- 根据特征向量的数据分布提出一个合适的模型函数$y=f(x;\theta)$来估计样本分布
    - $\theta$是模型函数中的参数，需要训练出最合适的模型的参数
- 提出一个合适的损失函数$L(x,y)$计算对于训练数据集上的所有训练样本估计的误差损失大小
    - 用损失函数估计误差，把所有样本的误差求均值，即模型的误差损失
    $$L(x,y) = \frac{1}{N}\sum_{i=1}^N{L(y_i,f(x_i))}$$
- 使用合适的优化算法使得损失函数带有参数的$L(x,y)$的值最小化，即：
    $$\min_{f \in F}{\frac{1}{N}\sum_{i=1}^N{L(y_i,f(x_i))}}$$
    - 调整参数$\theta$，使得损失最小
    - 用样本估计总体
- 求解最优化上述函数得到$L(y_i,f(x_i))$的最小值，从而得到原函数$y=f(x;\theta)$的参数$\theta$的解：
    $$\theta=(\theta^{(1)},\theta^{(2)},...,\theta^{(K)})$$
    - 其中参数个数K与模型函数$f(x;\theta)$相关，与特征向量维数以及数据个数无关，这样新的类标未知的样本$x$就可以直接输入到函数$f(x)$中，就可以得到新的预测类标$y$

---

<h4 id='5'>经验风险与结构风险</h4>

训练集上，损失函数越小是不是越好？

经验风险最小化
- 在求解模型时，优化目标仅仅包含对样本的估计的损失函数最小化，而没有对模型本身的复杂度进行控制
    $$\min_{f \in F}{\frac{1}{N}\sum_{i=1}^N{L(y_i,f(x_i))}}$$
- 缺点：学习出来的模型容易过拟合
    - 过拟合：对训练集上的样本具有很好的拟合能力，但是对未知样本拟合效果非常差

结构风险最小化
- 在求解模型时，优化目标不仅包含对样本估计的损失函数最小化，同时对模型本身的复杂度进行控制
    $$R_{srm} = {\frac{1}{N}\sum_{i=1}^N{L(y_i,f(x_i))}} + \lambda J(f)$$
    - 增加结构模型$J(f)$，使模型的参数$\theta$变得越来越小，越高阶的参数越小
- 优点：学习出来的模型不仅仅对训练集上的样本具有很好的拟合能力，并且对未知样本拟合效果也很好
    - 泛化能力：对未知样本的拟合能力

---

<h4 id='6'>模型的评估与选择</h4>

模型的评估

TP(True Positive)：正确预测的正样本数
FP(False Positive)：错误预测的正样本数
TN(True Negative)：正确预测的负样本数
FN(False Negative)：错误预测的负样本数

- 精确率（Precision）
    $$P=\frac{TP}{TP+FP}$$
    - 所有正样本中，预测正确的概率
- 召回率（Recall）
    $$R=\frac{TP}{TP+FN}$$
    - 所有预测为正的样本中，预测正确的概率
- 准确率
    $$\frac{TP+TN}{TP+FP+TN+FN}$$
    - 所有预测中，预测正确的概率
- ROC曲线与AUC值
    - 上述指标都只针对一次试验，具有偶然性
    - 对于多次预测，绘制ROC曲线，AUC即曲线下发面积
    - 曲线越趋向于左上角，AUC值越大，模型越好
- 一般选择AUC值作为评价标准

模型的选择

- 数据
    - 训练集（Training Set）：用于训练模型
    - 验证集（Validation Set）：用于模型的选择
    - 测试集（Test Set）：用于最终对学习方法的评估

- 交叉验证
    - k-折交叉验证
        - 在数据有限的情况下，将训练数据集随机地分为k个互不相交的大小相同的子集
        - 依次利用第k个子集作为测试集，其余k-1个子集作为训练集，训练出k个模型
        - 每个模型都有对应的误差，将平均测试误差作为该模型的误差
        - 选择误差最小的模型
    - 留一法
        - K-折交叉验证中，当K=N时，称为留一交叉验证
        - 适用于数据集比较缺乏的情况
        - 仅留一组数据作为测试集