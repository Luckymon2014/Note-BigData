***
目录

[微博数据分析平台架构解析](#1)
[微博数据分析平台数据存储模块设计与实现](#2)
[微博情感分析与单元测试](#3)
[微博用户使用终端分析与单元测试](#4)

***

<h4 id='1'>微博数据分析平台架构解析</h4>

1. 了解课程案例微博数据分析平台的架构
2. 了解常见的大数据平台架构

微博大数据分析

产品背景需求
- 微博舆情：危机管理、竞争情报、品牌分析
    - 负面信息
        - 影响范围
    - 竞争对手
        - 行业政策、新技术、新商业模式
        - 竞争对手动态，新产品、营销活动
    - 品牌形象
        - 媒体认知、网友认知、用户认知、意见领袖的态度

对于客户的价值
- 提升客户体验
- 创新商业模式
- 技术高效、低成本
- 提升业务效率
- 增强管理水平

服务体系
- 检测系统
    - 网络口碑监测
    - 热点事件监测
    - 行业竞品监测
- 危机预警
    - 邮件预警
    - 微信预警
    - 电话、手机短信预警
    - IM预警
    - ...
- 分析报告
    - 日/周/季/年报专题事件报告
    - 市场效果评估

整体架构
- 云采集
    - 定向抓取的智能爬虫、云搜索等多种机制，实时全网监测，数据采集
- 云存储
    - 分布式存储
    - 结构化、非结构化数据存储
    - 快照存储
    - 安全性
    - 高扩展性
- 云分析
    - 文章权重计算
    - 情感分析
    - 自动分类
    - 自动聚类
    - 传播轨迹
    - 自动发现
- 云应用
    - 前端界面

产品架构
- 应用层
    - J2EE
- 能力层
    - 基础分析
    - 多维分析
    - 数据挖掘
    - 实时分析
    - 自主分析
    - 数据共享
    - 数据统一服务，开放SQL、FTP、WX、MDX、API、...
- 数据层（混合数据中心架构）
    - 主数据仓库（Oracle、TeraData...）
        - 提供数据分析报表，直接面对业务用户
        - 离线分析业务，实时性要求低
    - 分布式数据库（MPP、SQLServer、SybaseIQ、HANA、Greenplum...）
        - Ad-hoc query，在大数据量上完成实时分析
        - Hadoop实时查询较慢，因此需要分布式数据库
    - Hadoop平台
        - 存储所有的数据
        - 完成基本统计分析
        - 目前无法完成真正的维度建模
        - 很少直面业务用户
- 获取层
    - 数据采集
        - ETL（数据的extract + transform + load）
            - 工具：Kettle, Talend, Niffi...
            - 收费：Infomatic, Datastage...
            - 对数据清洗流程进行调度
            - 封装清洗流程（可视化）
        - 流数据处理
        - 爬虫
- 数据源
    - 公司内部数据
    - 互联网

功能结构
- 微博分析应用
    - 微博声量分析
    - 微博情感分析
    - 微博转发评论分析
- 微博粉丝应用
    - 微博发帖用户归属地分析
    - 微博用户活跃度分析
- 微博品牌分析
    - 品牌粉丝画像
    - 微博账号用户画像

平台流程
- 提供需要监控的微博ID
- 通过微博的正则工具采集内容，变成文件（FTP、Linux共享目录），通过采集工具发给大数据平台

```mermaid
graph TD

微博ID库-->URL
URL-->采集端(采集端)
URL-->采集端2(采集端)
URL-->采集端3(采集端)
采集端2-->...2(......)
采集端3-->...3(......)

采集端-->完整网页
完整网页-->处理端(处理端:正则表达式)

subgraph 数据
    标题
    网站
    点击回复
    正文
    发布时间
    ...
end

处理端-->标题
处理端-->网站
处理端-->点击回复
处理端-->正文
处理端-->发布时间
处理端-->...

标题-->大数据平台
网站-->大数据平台
点击回复-->大数据平台
正文-->大数据平台
发布时间-->大数据平台
... -->大数据平台

正文-->处理端1(处理端:情感判断/聚类...)
正文-->处理端2(处理端:分词词库/分词算法)

subgraph 处理端
    处理端1
    处理端2
end

处理端1-->索引端
处理端2-->索引端

索引端---大数据平台

subgraph 前端交互
    用户-->前端
    前端-->查询条件
    查询条件-->索引端
    索引端-->查询结果
    查询结果-->前端
    前端-->最终信息
    最终信息-->用户
end
```

平台设计步骤
1. 业务需求制定分析
    - 离线分析业务（小时级，T+1）
        - 定时报表
        - 定时任务
    - 在线分析业务（分钟级）
        - 输入条件查询结果
        - 统计分析
    - 展现方法
        - ECharts
        - J2EE Tomcat
    - 数据存储需求
2. 软件规划
    - 大数据平台组件（离线分析）
    - 数据库软件
    - Web应用
    - BI组件
    - MPP数据库（在线分析）
    - 缓存（在线分析）
    - NoSQL数据库（在线分析）
3. 硬件规划
    - 离线分析集群
    - 在线分析集群
    - Web端应用集群
    - MPP集群
    - 缓存集群
    - NoSQL集群
    - 注：集群之间最好互相独立，便于管理，并且每个集群业务作用不同，对硬件的要求不同

本项目使用软件
- CDH 5.14
    - HDFS
    - Yarn
    - MapReduce
    - Hive
    - HBase
    - Flume
    - Sqoop
- MySQL 5.6
- JDK 1.8
- CentOS 7.0
- Web应用：Tomcat
- 报表：ECharts

***

<h4 id='2'>微博数据分析平台数据存储模块设计与实现</h4>

1. 了解课程案例微博数据分析平台的架构
2. 了解常见的HDFS企业目录规划方法
3. 实现企业微博数据分析平台数据存储目录实现以及数据装载及检查

数据存储模块需求
- 按天在HDFS中分开存储数据
    - 微博原始数据：/weibo_log/20180202
    - 微博情感分析数据：/weibo_log/emotion/20180202
    - hdfs dfs -put
- 每晚12点完菜数据在HDFS的加载，需要实现脚本实现，输出当前文件夹内的文件数以及文件大小
    - shell脚本调用hdfs命令，完成文件的加载
    - hdfs dfs -count

数据存储部署架构
- 主备NameNode + 4DataNode
- 3台Zookeeper
- 部署角度
    - DataNode和NameManager部署在一起
    - NameNode和ResourceManager部署在一起，可能分开
    - Zookeeper（HA管理），可以与DataNode在一起，服务器数量超过20台可以单独部署
- HDFS有三个副本，要求DataNode至少有4个，可以将DataNode和NameNode部署在一起
- NameNode重启时间较长，需要等全部的DataNode汇报Block信息
- 高可用
    - HA：NFS
        - 通过Zookeeper完成主备监测与切换
        - 通过NFS完成元数据的共享
        - NFS本身也需要HA，无法实时同步
        - 无法保证数据100%不丢失
    - HA：Journal Node(JN)
        - 互为主备
        - 是一种服务，部署在服务器上
        - 共享数据，保证数据不丢失

数据存储服务器数量估算
- 总空间合计*3/冗余系数（考虑是否压缩）
- 此项目中冗余系数：0.5
- 原始微博内容：每天1TB，保存2年，存储空间总需求为：2\*365\*1\*3/0.5≈4380TB
- MapReduce及Hive结果数据存储：每天产生约50GB，保存2年，存储空间总需求为：2\*365\*50\*3/0.5≈219TB
- HBase数据存储：每天产生100GB，保存6个月，存储空间总需求为：180\*100\*3/0.5≈108TB
- 项目总计存储空间需求：4380+219+108=4707TB
- 单台服务器24TB存储，满足2年使用需求，最低存储服务器数量需求为：196台

Shell脚本完成文件装载的逻辑
- \$1表示第一个参数，\$2表示第二个...
- 记录时间
    - starttime='data+'%Y-%m-%d%H:%M:%S''
- 装载hdfs文件：hdfs dfs -put
    - hdfs dfs -put \$1 hdfs://hadoop001:9000/web_log/\$2
- 统计文件数量：hdfs dfs -count
    - hdfs dfs -count hdfs://hadoop001:9000/web_log/\$2
- 记录时间
    - endtime='data+'%Y-%m-%d%H:%M:%S''
- start_seconds=\$(date--date="\$starttime"+%s);
- end_seconds=\$(date--date="\$starttime"+%s);
- 总时间：end_seconds - start_seconds


``` hdfs_web_log.sh
#! /bin/bash
#HDFS Web Log数据装载Shell脚本
#创建人：root
#创建时间：2018-08-01
#版本：v1
#功能：完成hdfs数据文件的导入，并且输出hdfs装载的文件数量
#输入参数：1.本地文件的文件夹路径 2.日期
#输出参数：1.任务的执行时间 2.装载的文件数量

echo "load file from $1"

#数据装载程序开始时间
starttime=`date +'%Y-%m-%d %H:%M:%S'`

#判断目录是否存在
hdfs dfs -test -e /web_log
if [ $? -eq 1 ] ;then hdfs dfs -mkdir hdfs://hadoop001:9000/web_log ;  fi
#执行装载
#hdfs dfs -mkdir hdfs://hadoop001:9000/web_log
hdfs dfs -put $1 hdfs://hadoop001:9000/web_log/$2

#数据装载程序结束时间
endtime=`date +'%Y-%m-%d %H:%M:%S'`

#整体程序执行时间
start_seconds=$(date --date="$starttime" +%s);
end_seconds=$(date --date="$endtime" +%s);
echo "执行时间："$((end_seconds - start_seconds))"s"
#文件数量
hdfs dfs -count hdfs://hadoop001:9000/web_log/$2
```

使用ETL工具，对Shell脚本进行定时执行

***

<h4 id='3'>微博情感分析与单元测试</h4>

1. 掌握MapReduce编程思路
2. 掌握微博情感分析业务逻辑

MapReduce流程
1. Input：数据从HDFS上输入
2. Splitting：将数据转为Key, Value格式
3. Mapping
4. Shuffling：默认使用Key的Hash值传送给Reducer
5. Reducing
6. Final Result

需求分析——微博情感分析
1. 根据已经给定的微博评论数据（正面、负面、中立）统计（按日）某人的所有微博的正负中性汇总
2. 在查询时，用户可以按照时间范围展示某条微博整体的情感情况，包括24小时，3天，7天
3. 结果生成字段：用户ID、日期、正面评价数量、负面评价数量、中性评价数量、正面数量占比、负面数量占比、中性数量占比
4. 页面展示时，需要计算用户选定的时间范围的微博统计数据
5. 结果通过HDFS存储

什么是微博情感分析
- 使用自然语言处理技术，对微博内容情感进行分类：正面、负面、中性
    - 贝叶斯算法、深度学习算法等

微博情感分析数据结构
- catchTime     抓取时间
- createTime    创建时间
- commentCount  评论次数
- praiseCount   点赞人数
- reportCount   转发人数
- userId        用户id
- weiboId       微博id
- neg_num       负面评论数量
- pos_num       正面评论数量
- neutral_num   中立情感数量

业务整体逻辑设计
- HDFS文件存储路径：/weibo_log/emotion/<date>
- MapReduce JAR
    - MapReduce情感分析：数据量统计程序逻辑
        1. 按照用户ID与日期做分组Key
        2. Value(负面评论数量，正面评论数量，中立情感数量)
        3. Reduce端分别对Value中的三个部分进行相加
    - MapReduce情感分析：占比逻辑
        1. 按照用户ID与日期做分组Key
        2. Map端(每日)使用数量除以总数
        3. Reduce端将全部的占比相加，得到全量的一个占比
- Shell脚本定时运行，将结果保存到：/weibo_log/emotion_analysis/<date>

***

<h4 id='4'>微博用户使用终端分析与单元测试</h4>

1. 掌握MapReduce编程实践案例
2. 实现MapReduce微博用户使用终端分析

需求分析——微博用户使用终端分析
1. 根据已给定的微博数据，统计（按日）不同终端使用情况
2. 在查询时，用户可以按照时间范围展示微博终端整体的使用情况，包括24小时，3天，7天
3. 结果生成字段：终端类型，日期，微博数量
4. 页面展示时，需要计算用户选定的时间范围的微博统计数量
5. 结果通过HDFS存储

Map个数计算
- splitSize = Math.max(minSize, Math.min(maxSize, blockSize))
    - minSize默认是1，FileInputFormat.setMinInputSplitSize(job, size)
    - maxSize默认是MAX_VALUE=0x7fffffffffffffffL，FileInputFormat.setMaxInputSplitSize(job, size)
    - blckSize默认是128M
- Map个数 = 输入文件大小 / splitSize
- Map数量一般不需要设置，由输入文件大小决定即可

Reduce个数计算
- Reduce个数由partition个数决定
    - HashPartitioner.getPartition
        - (key.hashCode() & Integer.MAX_VALUE) % numReduceTasks
- Reduce个数 = min(max(totalInputFileSize / 单个reduce接受数据大小bytesPerReducer, 1), maxReducers)
    - totalInputFileSize输入文件大小，指Map端输出的文件
    - bytesPerReducer默认256M
    - maxReducers默认1094
- job.setNumReduceTasks(reduceNum)

微博数据结构
- beCommentWeiboId  是否评论
- beForwardWeiboId  是否是转发微博
- catchTime         抓取时间
- commentCount      评论次数
- content           内容
- createTime        创建时间
- info1             信息字段1
- info2             信息字段2
- info3             信息字段3
- mlevel no sure
- musicurl          音乐链接
- pic_list          照片列表（可以有多个）
- praiseCount       点赞人数
- reportCount       转发人数
- source            数据来源
- userId            用户id
- videourl          视频链接
- weiboId           微博id
- weiboUrl          微博网址

业务整体逻辑设计
- HDFS文件存储路径：/weibo_log/<date>
- MapReduce JAR
    1. 按照微博终端与日期分组Key，Value(1)
    2. Reduce端分别对Value进行相加
- Shell脚本定时运行，将结果保存到：/weibo_log/source_analysis/<date>

实战中解决参数硬编码
- new GenericOptionsParser(conf, args).getRemainingArgs()
    - 获取命令行写入的参数，传入程序并自动设置
    - files：上传指定文件到HDFS中MapReduce临时目录，并允许Map和Reduce任务读取到他
    - libjars：上传本地的jar包到HDFS中MapReduce临时目录并将其设置到Map和Reduce任务的classpath中
    - 通过DistributeCache实现
        - 每一个map的内存中，生成一个缓存区域来存放数据，该数据可能很小，从而达到提升性能的目的
- extends Configured implements Tool
    - run()
    - 自动调用GenericOptionsParser